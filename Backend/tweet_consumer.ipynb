{"cells": [{"cell_type": "markdown", "id": "1a801701-bd23-4f1d-af9d-efd8a746d8e8", "metadata": {}, "source": "https://towardsdatascience.com/my-absolute-go-to-for-sentiment-analysis-textblob-3ac3a11d524"}, {"cell_type": "code", "execution_count": 1, "id": "173343e9-5d0a-4398-8c89-39dc9a846538", "metadata": {}, "outputs": [], "source": "# Note - Output folder must be public to the internet\nis_realtime = False\nproject_bucket_name = \"cloud-project-bucket-ns-22\"\ntopic = \"Batman\"\ninput_folder_name = 'gs://{}/Input/{}/'.format(project_bucket_name, topic)\noutput_folder_name = 'gs://{}/Output/{}/'.format(project_bucket_name, topic)"}, {"cell_type": "code", "execution_count": 2, "id": "64142eb6-689c-40b6-91fe-cd038b019028", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied: textblob in /opt/conda/miniconda3/lib/python3.8/site-packages (0.17.1)\nRequirement already satisfied: nltk>=3.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from textblob) (3.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2022.3.2)\nRequirement already satisfied: tqdm in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.63.0)\nRequirement already satisfied: click in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (7.1.2)\nRequirement already satisfied: joblib in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: findspark in /opt/conda/miniconda3/lib/python3.8/site-packages (2.0.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m"}], "source": "!pip install textblob\n!pip install findspark"}, {"cell_type": "code", "execution_count": 3, "id": "811353a4-a608-46a7-a3ab-9fc027e86767", "metadata": {}, "outputs": [], "source": "# import necessary packages\nimport os\nimport json\nimport time\nimport subprocess\nimport pyspark\nimport findspark\nimport socket\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nfrom textblob import TextBlob\n\nfrom IPython.display import clear_output"}, {"cell_type": "code", "execution_count": 4, "id": "9713fff8", "metadata": {}, "outputs": [], "source": "findspark.init()"}, {"cell_type": "code", "execution_count": 5, "id": "4c8407aa-efd0-49f8-9206-7c5c1297abd9", "metadata": {}, "outputs": [], "source": "def json_load(text):\n    return json.loads(text)"}, {"cell_type": "code", "execution_count": 6, "id": "9b576e31-21bf-458f-a431-014a6a81f761", "metadata": {}, "outputs": [], "source": "def get_message(text):\n    msg = json.loads(text)\n    # if tweet is longer than 140 characters\n    if \"extended_tweet\" in msg:\n        return str(msg['extended_tweet']['full_text'])\n    else:\n        return str(msg['text'])"}, {"cell_type": "code", "execution_count": 7, "id": "9e9e4a2d-6050-4e46-96e5-4f023aa18673", "metadata": {}, "outputs": [], "source": "def get_tweet_field(text, field):\n    msg = json.loads(text)\n    if '/' in field:\n        fields = field.split('/')\n        fieldDepth = len(fields)\n        f = msg\n        for i in range(fieldDepth):\n            if(f is None):\n                return None\n            if i == fieldDepth - 1:\n                return str(f[fields[i]]) \n            else:\n                f = f[fields[i]]\n    else:\n        return str(msg[field])"}, {"cell_type": "code", "execution_count": 8, "id": "0077686e-aed4-418e-9e49-9723877afa68", "metadata": {}, "outputs": [], "source": "def get_analysis(score):\n    if score < 0:\n        return 'Negative'\n    elif score == 0:\n        return 'Neutral'\n    else:\n        return 'Positive'"}, {"cell_type": "code", "execution_count": 9, "id": "69517450-b31a-44b7-8000-00ccc59bcb24", "metadata": {}, "outputs": [], "source": "def process_tweets(tweets):\n    \n#     # Convert to json\n#     json_load_udf = udf(json_load, StringType())\n#     tweets = tweets.withColumn(\"json\", json_load_udf(\"value\"))\n    \n    # Get id\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"id\", get_tweet_field_udf(\"value\", lit('id')))\n    \n    # Get created_at\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"created_at\", get_tweet_field_udf(\"value\", lit('created_at')))\n    \n    # Get place full name\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"place_full_name\", get_tweet_field_udf(\"value\", lit('place/full_name')))\n    \n    # Get place country\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"place_country\", get_tweet_field_udf(\"value\", lit('place/country')))\n    \n    # Get place country code\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"place_country_code\", get_tweet_field_udf(\"value\", lit('place/country_code')))\n    \n    # Get message\n    get_message_udf = udf(get_message, StringType())\n    tweets = tweets.withColumn(\"message\", get_message_udf(\"value\"))\n    \n    # Get cleaned words from message for analysis\n    #tweets = tweets.na.replace('', None)\n    #tweets = tweets.na.drop()\n    tweets = tweets.withColumn('words', tweets.message)\n    tweets = tweets.withColumn('words', F.regexp_replace('words', r'http\\S+', ''))\n    tweets = tweets.withColumn('words', F.regexp_replace('words', '@\\w+', ''))\n    tweets = tweets.withColumn('words', F.regexp_replace('words', '#', ''))\n    tweets = tweets.withColumn('words', F.regexp_replace('words', 'RT', ''))\n    tweets = tweets.withColumn('words', F.regexp_replace('words', ':', ''))\n    \n    # Drop unnesscessary data\n    tweets = tweets.drop(\"value\")\n    #tweets = tweets.drop(\"json\")\n    \n    return tweets"}, {"cell_type": "code", "execution_count": 10, "id": "be430afc-52f8-4665-90ed-9fd2a61910cd", "metadata": {}, "outputs": [], "source": "# Text classification using TextBlob\ndef polarity_detection(text):\n    return TextBlob(text).sentiment.polarity\ndef subjectivity_detection(text):\n    return TextBlob(text).sentiment.subjectivity\ndef text_classification(tweets):\n    \n    # polarity detection\n    polarity_detection_udf = udf(polarity_detection, StringType())\n    tweets = tweets.withColumn(\"polarity\", polarity_detection_udf(\"words\"))\n    \n    # subjectivity detection\n    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n    tweets = tweets.withColumn(\"subjectivity\", subjectivity_detection_udf(\"words\"))\n    \n    # analysis\n    get_analysis_udf = udf(get_analysis, StringType())\n    tweets = tweets.withColumn('analysis', get_analysis_udf('polarity'))\n    \n    return tweets"}, {"cell_type": "code", "execution_count": 11, "id": "34cf69ea-0a49-4f50-89a1-0fa66e674f77", "metadata": {"tags": []}, "outputs": [], "source": "def start_offline_batch_processing(spark):\n    # Read files from input folder\n    df_folder = spark.read.text(input_folder_name)\n    lines = df_folder\n    \n    # Process and classify tweets\n    tweets = process_tweets(lines)\n    tweets = text_classification(tweets)\n    tweets.createOrReplaceTempView(\"tweets\")\n    \n    # Create output file names\n    df_sentiment_by_country_output_file_name = output_folder_name + \"df_sentiment_by_country.csv\"\n    df_sentiment_by_country = spark.sql('SELECT place_country as Country, place_country_code as CountryCode, avg(polarity) as Sentiment, count(id) as TweetCount FROM tweets GROUP BY place_country, place_country_code ORDER BY place_country_code')\n    \n    # Write to single files\n    #df_country_sentiment.repartition(1).write.mode(\"overwrite\").option(\"header\",True).csv(countrySentimentOutputFileName)\n    #df_country_sentiment.coalesce(1).write.mode(\"overwrite\").option(\"header\",True).csv(countrySentimentOutputFileName)\n    df_sentiment_by_country.toPandas().to_csv(df_sentiment_by_country_output_file_name, index=False)\n    print(\"File '{}' updated...\".format(df_sentiment_by_country_output_file_name))\n    \n    return tweets"}, {"cell_type": "code", "execution_count": 12, "id": "d1411f22-a06d-4cd8-a9fb-a7527c36af09", "metadata": {}, "outputs": [], "source": "def process_stream_batch(df, batch_id, output_file_name):\n    # Write to single file\n    #df.repartition(1).write.mode(\"overwrite\").option(\"header\",True).csv(outputFileName)\n    #df.coalesce(1).write.mode(\"overwrite\").option(\"header\",True).csv(outputFileName)\n    df.toPandas().to_csv(output_file_name, index=False)\n    print(\"File '{}' updated, batch_id = {}...\".format(output_file_name, batch_id))"}, {"cell_type": "code", "execution_count": 13, "id": "29da4c29-c880-4edc-909a-858b577e9888", "metadata": {}, "outputs": [], "source": "def get_batched_file_stream():\n    # Stream files from input folder\n    file_stream = spark.readStream.format('text').option(\"maxFilesPerTrigger\", 5).load(input_folder_name)\n    print(\"Batched file stream...\")\n    return file_stream"}, {"cell_type": "code", "execution_count": 14, "id": "ebbd79cf-e6a8-4dbe-9de6-ddd6dfde6ca5", "metadata": {}, "outputs": [], "source": "def get_realtime_stream():\n    # Socket connection stream\n    socket_stream = spark.readStream \\\n                    .format(\"socket\") \\\n                    .option(\"host\", socket.gethostname()) \\\n                    .option(\"port\", 5555) \\\n                    .load()\n    print(\"Real-time socket stream...\")\n    return socket_stream"}, {"cell_type": "code", "execution_count": 15, "id": "40da72f6-2154-42c7-a493-116f0c7179c3", "metadata": {}, "outputs": [], "source": "def start_stream_processing(spark, is_realtime=False):\n    # Get tweet stream\n    lines = get_realtime_stream() if is_realtime else get_batched_file_stream()\n    \n    # Process and classify tweets\n    tweets = process_tweets(lines)\n    tweets = text_classification(tweets)\n    tweets.createOrReplaceTempView(\"tweets\")\n    \n    # Create output file names\n    df_sentiment_by_country_output_file_name = output_folder_name + \"df_sentiment_by_country_streaming.csv\"\n    df_sentiment_by_category_output_file_name = output_folder_name + \"df_sentiment_by_category_streaming.csv\"\n\n    # Create streaming queries\n    df_sentiment_by_country = spark.sql('SELECT place_country as Country, place_country_code as CountryCode, avg(polarity) as Sentiment, count(id) as TweetCount FROM tweets GROUP BY place_country, place_country_code')\n    df_sentiment_by_country_query = df_sentiment_by_country.writeStream.outputMode('complete').foreachBatch(lambda df, epoch_id: process_stream_batch(df, epoch_id, df_sentiment_by_country_output_file_name)).start()\n    \n    df_sentiment_by_category = spark.sql('SELECT analysis as Sentiment, count(id) as TweetCount FROM tweets GROUP BY analysis')\n    df_sentiment_by_category_query = df_sentiment_by_category.writeStream.outputMode('complete').foreachBatch(lambda df, epoch_id: process_stream_batch(df, epoch_id, df_sentiment_by_category_output_file_name)).start()\n    \n    spark.streams.awaitAnyTermination()"}, {"cell_type": "code", "execution_count": null, "id": "4042f9e4-8571-4872-b1ad-2d48c945bf0b", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Batched file stream...\n"}, {"name": "stderr", "output_type": "stream", "text": "22/03/16 21:16:22 WARN org.apache.spark.sql.streaming.StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-36a7fac8-59da-4d04-8692-1f9edbae1cc4. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n22/03/16 21:16:22 WARN org.apache.spark.sql.streaming.StreamingQueryManager: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n22/03/16 21:16:22 WARN org.apache.spark.sql.streaming.StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-cc5ac82f-a2b2-4bb4-9c0f-1ee508ec4bcd. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n22/03/16 21:16:22 WARN org.apache.spark.sql.streaming.StreamingQueryManager: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 0...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 0...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 1...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 1...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 2...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 2...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 3...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 3...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 4...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 4...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 5...\nFile 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 5...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 6...\nFile 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 6...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 7...\nFile 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 7...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 8...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 8...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 9...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 9...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 10...\nFile 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 10...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 11...\nFile 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 11...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 12...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 12...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 13...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 13...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 14...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 14...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 15...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 15...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 16...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 16...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 17...\nFile 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 17...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 18...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 18...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 19...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 19...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 20...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 20...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_country_streaming.csv' updated, batch_id = 21...\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "File 'gs://cloud-project-bucket-ns-22/Output/Batman/df_sentiment_by_category_streaming.csv' updated, batch_id = 21...\n"}, {"name": "stderr", "output_type": "stream", "text": "22/03/16 21:20:47 WARN org.apache.spark.sql.execution.streaming.FileStreamSource: Listed 110 file(s) in 5538 ms\n"}], "source": "#if __name__ == \"__main__\":\n\n# Create Spark session\nspark = SparkSession.builder.appName(\"TwitterTopicSentimentAnalysis\").getOrCreate()\n\n# Start offline batch processing\n#tweets = start_offline_batch_processing(spark)\n\n# Start stream processing\nstart_stream_processing(spark, is_realtime)"}, {"cell_type": "code", "execution_count": null, "id": "694d05f2-25e2-4682-a937-39c123b92b7a", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"interpreter": {"hash": "aea1e1c6019b0b94b776c1de20443eea7958a54dce1cb1d96e169a524b7b6729"}, "kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}