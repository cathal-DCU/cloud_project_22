{"cells": [{"cell_type": "markdown", "id": "1a801701-bd23-4f1d-af9d-efd8a746d8e8", "metadata": {}, "source": "https://towardsdatascience.com/my-absolute-go-to-for-sentiment-analysis-textblob-3ac3a11d524"}, {"cell_type": "code", "execution_count": null, "id": "173343e9-5d0a-4398-8c89-39dc9a846538", "metadata": {}, "outputs": [], "source": "# Note - Output folder must be public to the internet\nis_realtime = False\nproject_bucket_name = \"cloud-project-bucket-ns-22\"\ntopic = \"Batman\"\ninput_folder_name = 'gs://{}/Input/{}/'.format(project_bucket_name, topic)\noutput_folder_name = 'gs://{}/Output/{}/'.format(project_bucket_name, topic)"}, {"cell_type": "code", "execution_count": null, "id": "64142eb6-689c-40b6-91fe-cd038b019028", "metadata": {}, "outputs": [], "source": "!pip install textblob\n!pip install findspark"}, {"cell_type": "code", "execution_count": null, "id": "811353a4-a608-46a7-a3ab-9fc027e86767", "metadata": {}, "outputs": [], "source": "# import necessary packages\nimport os\nimport json\nimport time\nimport subprocess\nimport pyspark\nimport findspark\nimport socket\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Window\nfrom pyspark import Row\nfrom textblob import TextBlob\n\nfrom IPython.display import clear_output"}, {"cell_type": "code", "execution_count": null, "id": "9713fff8", "metadata": {}, "outputs": [], "source": "findspark.init()"}, {"cell_type": "code", "execution_count": null, "id": "4c8407aa-efd0-49f8-9206-7c5c1297abd9", "metadata": {}, "outputs": [], "source": "def json_load(text):\n    return json.loads(text)"}, {"cell_type": "code", "execution_count": null, "id": "9b576e31-21bf-458f-a431-014a6a81f761", "metadata": {}, "outputs": [], "source": "def get_message(text):\n    msg = json.loads(text)\n    # if tweet is longer than 140 characters\n    if \"extended_tweet\" in msg:\n        return str(msg['extended_tweet']['full_text'])\n    else:\n        return str(msg['text'])"}, {"cell_type": "code", "execution_count": null, "id": "9e9e4a2d-6050-4e46-96e5-4f023aa18673", "metadata": {}, "outputs": [], "source": "def get_tweet_field(text, field):\n    msg = json.loads(text)\n    if '/' in field:\n        fields = field.split('/')\n        fieldDepth = len(fields)\n        f = msg\n        for i in range(fieldDepth):\n            if(f is None):\n                return None\n            if i == fieldDepth - 1:\n                return str(f[fields[i]]) \n            else:\n                f = f[fields[i]]\n    else:\n        return str(msg[field])"}, {"cell_type": "code", "execution_count": null, "id": "0077686e-aed4-418e-9e49-9723877afa68", "metadata": {}, "outputs": [], "source": "def get_analysis(score):\n    if score < 0:\n        return 'Negative'\n    elif score == 0:\n        return 'Neutral'\n    else:\n        return 'Positive'"}, {"cell_type": "code", "execution_count": null, "id": "f4ec42d8-5608-4087-9436-398faf5aee6e", "metadata": {}, "outputs": [], "source": "def process_tweets(tweets):\n\n    # Get id\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"id\", get_tweet_field_udf(\"value\", lit('id')))\n\n    # Get created_at\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"created_at\", get_tweet_field_udf(\"value\", lit('created_at')))\n\n    # Get place full name\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"place_full_name\", get_tweet_field_udf(\"value\", lit('place/full_name')))\n\n    # Get place country\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"place_country\", get_tweet_field_udf(\"value\", lit('place/country')))\n\n    # Get place country code\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"place_country_code\", get_tweet_field_udf(\"value\", lit('place/country_code')))\n\n    # Get place co-ordinates\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"place_coordinates\", get_tweet_field_udf(\"value\", lit('coordinates')))\n\n    # Get place bounding_box co-ordinates\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"bounding_box_coordinates\",\n                               get_tweet_field_udf(\"value\", lit('place/bounding_box/coordinates')))\n\n    # Get place type\n    get_tweet_field_udf = udf(get_tweet_field, StringType())\n    tweets = tweets.withColumn(\"place_type\", get_tweet_field_udf(\"value\", lit('place/place_type')))\n\n    # Get message\n    get_message_udf = udf(get_message, StringType())\n    tweets = tweets.withColumn(\"message\", get_message_udf(\"value\"))\n\n    # Get cleaned words from message for analysis\n    tweets = tweets.withColumn('words', tweets.message)\n    # Remove HTML special entities (e.g. &amp;)\n    tweets = tweets.withColumn('words', F.regexp_replace('words', r'\\&\\w*;', ''))\n    # Convert @username to AT_USER\n    tweets = tweets.withColumn('words', F.regexp_replace('words', '@[^\\s]+', ''))\n    # Remove tickers\n    tweets = tweets.withColumn('words', F.regexp_replace('words', r'\\$\\w*', ' '))\n    # Remove hyperlinks\n    tweets = tweets.withColumn('words', F.regexp_replace('words', r'https?:\\/\\/.*\\/\\w*', ''))\n    # Remove hashtags\n    tweets = tweets.withColumn('words', F.regexp_replace('words', r'#\\w*', ''))\n    # Remove words with 2 or fewer letters\n    # tweets = tweets.withColumn('words', F.regexp_replace('words', r'\\b\\w{1,2}\\b', ''))\n    # Remove whitespace (including new line characters)\n    tweets = tweets.withColumn('words', F.regexp_replace('words', r'\\s\\s+', ' '))\n    tweets = tweets.withColumn('words', F.regexp_replace('words', r'http\\S+', ' '))\n    # tweets = tweets.withColumn('words', F.regexp_replace('words', '@\\w+', ' '))\n    # tweets = tweets.withColumn('words', F.regexp_replace('words', '#', ' '))\n    tweets = tweets.withColumn('words', F.regexp_replace('words', 'RT', ''))\n    # tweets = tweets.withColumn('words', F.regexp_replace('words', ':', ' '))\n\n    # Drop unnesscessary data\n    tweets = tweets.drop(\"value\")\n\n    return tweets"}, {"cell_type": "code", "execution_count": null, "id": "be430afc-52f8-4665-90ed-9fd2a61910cd", "metadata": {}, "outputs": [], "source": "# Text classification using TextBlob\ndef polarity_detection(text):\n    return TextBlob(text).sentiment.polarity\ndef subjectivity_detection(text):\n    return TextBlob(text).sentiment.subjectivity\ndef text_classification(tweets):\n    \n    # polarity detection\n    polarity_detection_udf = udf(polarity_detection, StringType())\n    tweets = tweets.withColumn(\"polarity\", polarity_detection_udf(\"words\"))\n    \n    # subjectivity detection\n    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n    tweets = tweets.withColumn(\"subjectivity\", subjectivity_detection_udf(\"words\"))\n    \n    # analysis\n    get_analysis_udf = udf(get_analysis, StringType())\n    tweets = tweets.withColumn('analysis', get_analysis_udf('polarity'))\n    \n    return tweets"}, {"cell_type": "code", "execution_count": null, "id": "34cf69ea-0a49-4f50-89a1-0fa66e674f77", "metadata": {"tags": []}, "outputs": [], "source": "def start_offline_batch_processing(spark):\n    # Read files from input folder\n    df_folder = spark.read.text(input_folder_name)\n    lines = df_folder\n    \n    # Process and classify tweets\n    tweets = process_tweets(lines)\n    tweets = text_classification(tweets)\n    tweets.createOrReplaceTempView(\"tweets\")\n    \n    # Create output file names\n    df_sentiment_by_country_output_file_name = output_folder_name + \"df_sentiment_by_country.csv\"\n    df_sentiment_by_country = spark.sql('SELECT place_country as Country, place_country_code as CountryCode, avg(polarity) as Sentiment, count(id) as TweetCount FROM tweets GROUP BY place_country, place_country_code ORDER BY place_country_code')\n    \n    # Write to single files\n    df_sentiment_by_country.toPandas().to_csv(df_sentiment_by_country_output_file_name, index=False)\n    print(\"File '{}' updated...\".format(df_sentiment_by_country_output_file_name))\n    \n    return tweets"}, {"cell_type": "code", "execution_count": null, "id": "29da4c29-c880-4edc-909a-858b577e9888", "metadata": {}, "outputs": [], "source": "def get_batched_file_stream():\n    # Stream files from input folder\n    file_stream = spark.readStream.format('text').option(\"maxFilesPerTrigger\", 5).load(input_folder_name)\n    print(\"Batched file stream...\")\n    return file_stream"}, {"cell_type": "code", "execution_count": null, "id": "ebbd79cf-e6a8-4dbe-9de6-ddd6dfde6ca5", "metadata": {}, "outputs": [], "source": "def get_realtime_stream():\n    # Socket connection stream\n    socket_stream = spark.readStream \\\n                    .format(\"socket\") \\\n                    .option(\"host\", socket.gethostname()) \\\n                    .option(\"port\", 5555) \\\n                    .load()\n    print(\"Real-time socket stream...\")\n    return socket_stream"}, {"cell_type": "code", "execution_count": null, "id": "0c7516a6-d8a2-4130-a98c-2881af3fe412", "metadata": {}, "outputs": [], "source": "def get_sentiment_by_country_query():\n    return 'SELECT place_country as Country, place_country_code as CountryCode, avg(polarity) as Sentiment, count(id) as TweetCount FROM tweets GROUP BY place_country, place_country_code'"}, {"cell_type": "code", "execution_count": null, "id": "5e03fc9d-8663-46c0-9713-662a3e547418", "metadata": {}, "outputs": [], "source": "def get_sentiment_by_category_query():\n    return 'SELECT analysis as Sentiment, count(id) as TweetCount FROM tweets GROUP BY analysis'"}, {"cell_type": "code", "execution_count": null, "id": "51427ed3-70fd-4958-b594-b9ef16927bbc", "metadata": {}, "outputs": [], "source": "def write_to_file(df, batch_id, output_file_name): \n    # Write to single file\n    df.show()\n    #df.repartition(1).write.mode(\"overwrite\").option(\"header\",True).csv(outputFileName)\n    #df.coalesce(1).write.mode(\"overwrite\").option(\"header\",True).csv(outputFileName)\n    df.toPandas().to_csv(output_file_name, index=False)\n    print(\"File '{}' updated, batch_id = {}...\".format(output_file_name, batch_id))"}, {"cell_type": "code", "execution_count": null, "id": "fe164b0b-6b12-472c-aead-b6245054a891", "metadata": {}, "outputs": [], "source": "def start_stream_processing(spark, is_realtime=False):\n    # Get tweet stream\n    lines = get_realtime_stream() if is_realtime else get_batched_file_stream()\n    \n    # Process and classify tweets\n    tweets = process_tweets(lines)\n    tweets = text_classification(tweets)\n    tweets.createOrReplaceTempView(\"tweets\")\n    \n    # Create by country streaming query\n    df_sentiment_by_country_output_file_name = output_folder_name + \"df_sentiment_by_country_streaming.csv\"\n    df_sentiment_by_country = spark.sql(get_sentiment_by_country_query())\n    df_sentiment_by_country_query = df_sentiment_by_country.writeStream\\\n    .format(\"memory\")\\\n    .queryName(\"df_sentiment_by_country_query\")\\\n    .outputMode(\"complete\")\\\n    .foreachBatch(lambda df, batch_id: write_to_file(df, batch_id, df_sentiment_by_country_output_file_name)) \\\n    .start()\n    #.trigger(processingTime='5 seconds')\\\n    \n    # Create by category streaming query\n    df_sentiment_by_category_output_file_name = output_folder_name + \"df_sentiment_by_category_streaming.csv\"\n    df_sentiment_by_category = spark.sql(get_sentiment_by_category_query())\n    df_sentiment_by_category_query = df_sentiment_by_category.writeStream\\\n    .format(\"memory\")\\\n    .queryName(\"df_sentiment_by_category_query\")\\\n    .outputMode(\"complete\")\\\n    .foreachBatch(lambda df, batch_id: write_to_file(df, batch_id, df_sentiment_by_category_output_file_name)) \\\n    .start()\n    #.trigger(processingTime='5 seconds')\\\n    \n    # Await termination\n    spark.streams.awaitAnyTermination()"}, {"cell_type": "code", "execution_count": null, "id": "4042f9e4-8571-4872-b1ad-2d48c945bf0b", "metadata": {"tags": []}, "outputs": [], "source": "#if __name__ == \"__main__\":\n\n# Create Spark session\nspark = SparkSession.builder.appName(\"TwitterTopicSentimentAnalysis\").getOrCreate()\n\n# Start stream processing\nstart_stream_processing(spark, is_realtime)"}], "metadata": {"interpreter": {"hash": "aea1e1c6019b0b94b776c1de20443eea7958a54dce1cb1d96e169a524b7b6729"}, "kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}