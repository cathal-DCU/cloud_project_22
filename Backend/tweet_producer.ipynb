{"cells": [{"cell_type": "markdown", "id": "1a801701-bd23-4f1d-af9d-efd8a746d8e8", "metadata": {}, "source": "https://towardsdatascience.com/my-absolute-go-to-for-sentiment-analysis-textblob-3ac3a11d524"}, {"cell_type": "code", "execution_count": null, "id": "85ab00ed-bc22-4e6b-b8d3-faba25d4cd5a", "metadata": {}, "outputs": [], "source": "# Note - Output folder must be public to the internet\nis_realtime = False\nproject_bucket_name = \"cloud-project-bucket-ns-22\"\ntopic = \"Batman\"\nbatch_size = 1000\ninput_folder_name = 'Input/{}/'.format(topic)\n\n# request to get credentials at http://apps.twitter.com\nconsumer_key    = '3XwgFgsXucaFXOrkZtlwvxV5O'\nconsumer_secret = 'LNnTcxibKalylVImljDsKfkRqb6WHD8I7hdSYt7Pm7VaCetqZm'\naccess_token    = '608048932-AM21gcwLORlm5j0514DwPL850byLb7Gs04bPZ6Mn'\naccess_token_secret   = 'QtnJ8mV75peV7L7Kd4DZKogMRIxzjk5XFOPtZiz62NoM3'"}, {"cell_type": "code", "execution_count": null, "id": "64142eb6-689c-40b6-91fe-cd038b019028", "metadata": {}, "outputs": [], "source": "import os\nimport sys\nimport time\nimport json\nimport socket\nfrom google.cloud import storage\n\nfrom IPython.display import clear_output"}, {"cell_type": "code", "execution_count": null, "id": "4cfad26b-9fb3-49ae-a881-5021a1a60d2a", "metadata": {}, "outputs": [], "source": "import os\nimport re\nimport time\nimport json\nimport socket\n\nimport tweepy\nfrom tweepy import Stream\n\n\n# Documentation - https://docs.tweepy.org/en/stable/streaming.html\n# Inherits from the Stream in tweepy - provides additional functionality\nclass TweetStream(Stream):\n    \n    def __init__(self, consumer_key, consumer_secret, access_token, access_token_secret, client_connection=None, rate_limit_delay=None, time_limit=None, tweet_limit=None, message_Handler=None, batch_size=None, batch_handler=None):\n        \n        # Set client connection\n        self.client_connection = client_connection\n\n        # Set rate limt\n        self.rate_limit_delay = rate_limit_delay\n\n        # Set time limit\n        self.start_time = time.time()\n        self.time_limit = time_limit\n        \n        # Set tweet limit\n        self.tweet_limit = tweet_limit\n        self.tweet_count = 0\n\n        # Set batching\n        self.batch_size = batch_size\n        self.batch_handler = batch_handler\n        self.batch = []\n\n        # Set message handler\n        self.message_handler = message_Handler\n        \n        # Initialize super\n        super(TweetStream, self).__init__(consumer_key, consumer_secret, access_token, access_token_secret)\n        \n    def check_continue_time_limit(self):\n        \n        # Check time limit if set\n        if self.time_limit is not None:\n            if (time.time() - self.start_time) > self.time_limit:\n                return False\n        return True\n    \n    def check_continue_tweet_limit(self):\n        # Check tweet limit if set\n        if self.tweet_limit is not None:\n            if self.tweet_limit <= self.tweet_count :\n                return False\n        return True\n\n    def close_connections(self):\n        \n        # Process batch before disconnecting\n        self.process_batch(is_disconnecting=True)\n\n        print(\"Disconnecting...\")\n\n        # Disconnect client connection if provided\n        if self.client_connection is not None:\n           self.client_connection.close()\n\n        # Disconnect stream\n        self.disconnect()\n\n        print(\"Disconnected.\")\n\n\n    def send_to_client(self, data):\n\n        if self.client_connection is not None:\n            # Send tweet data to client connection\n            self.client_connection.send(data)\n\n            # Send new line delimiter to client connection\n            self.client_connection.send(str('\\n').encode('utf-8'))\n\n\n    def process_batch(self, is_disconnecting=False):\n        if self.batch_size is not None:\n            if len(self.batch) == self.batch_size or (is_disconnecting == True and len(self.batch) > 0):\n                # Write to batch handler if provided\n                if self.batch_handler is not None:\n                    self.batch_handler(self.batch)\n            \n                # Write to client connection if provided\n                self.send_to_client(self.batch)\n\n                # Clear batch\n                self.batch.clear()\n\n\n    def on_data(self, data):\n        try:\n            \n            # Check for time limit\n            if self.check_continue_time_limit() is False:\n                print('Time limit hit.')\n                self.close_connections()\n                return False\n\n            # Check for tweet limit\n            if self.check_continue_tweet_limit() is False:\n                print('Tweet limit hit.')\n                self.close_connections()\n                return False\n            \n            # Check for limit message from twitter\n            if '{\"limit\":' in str(data):\n                print('Twitter rate limit - {}'.format(str(data)))\n                return True\n\n            # Process batch\n            if self.batch_size is not None:\n                self.batch.append(data)\n                self.process_batch()\n\n            # Write to message handler if provided\n            if self.message_handler is not None:\n                self.message_handler(data)\n\n            # Write to client connection if provided\n            if self.client_connection is not None:\n                self.send_to_client(data)\n\n            # Update tweet count\n            self.tweet_count = self.tweet_count + 1\n\n            # Check for rate limit delay\n            if self.rate_limit_delay is not None:\n                time.sleep(self.rate_limit_delay)\n                \n        except BaseException as e:\n            print(\"Error on_data: %s\" % str(e))\n            self.close_connections()\n            return False\n        \n        return True\n\n    def if_error(self, status):\n        print(status)\n        return True"}, {"cell_type": "code", "execution_count": null, "id": "3aeae0ff-6593-4d0f-95bf-f95d5413e026", "metadata": {}, "outputs": [], "source": "def upload_blob_from_memory(bucket_name, contents, destination_blob_name):\n    \"\"\"Uploads a file to the bucket.\"\"\"\n\n    # The ID of your GCS bucket\n    # bucket_name = \"your-bucket-name\"\n\n    # The contents to upload to the file\n    # contents = \"these are my contents\"\n\n    # The ID of your GCS object\n    # destination_blob_name = \"storage-object-name\"\n\n    storage_client = storage.Client()\n    bucket = storage_client.bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n\n    blob.upload_from_string(contents)\n\n    print(\"{} uploaded to {}.\".format(destination_blob_name, bucket_name))"}, {"cell_type": "code", "execution_count": null, "id": "bec12236-7ace-4d3d-a01d-bd221676ae18", "metadata": {}, "outputs": [], "source": "def download_blob(bucket_name, source_blob_name, destination_file_name):\n    \"\"\"Downloads a blob from the bucket.\"\"\"\n    # The ID of your GCS bucket\n    # bucket_name = \"your-bucket-name\"\n\n    # The ID of your GCS object\n    # source_blob_name = \"storage-object-name\"\n\n    # The path to which the file should be downloaded\n    # destination_file_name = \"local/path/to/file\"\n\n    storage_client = storage.Client()\n    bucket = storage_client.bucket(bucket_name)\n\n    # Construct a client side representation of a blob.\n    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n    # any content from Google Cloud Storage. As we don't need additional data,\n    # using `Bucket.blob` is preferred here.\n    blob = bucket.blob(source_blob_name)\n    blob.download_to_filename(destination_file_name)\n    #content = blob.download_as_string()\n\n    print(\n        \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n            source_blob_name, bucket_name, destination_file_name\n        )\n    )"}, {"cell_type": "code", "execution_count": null, "id": "e2732896-ee40-487b-8b7c-73d627ba8172", "metadata": {}, "outputs": [], "source": "def download_blob_as_string(bucket_name, source_blob_name):\n    \"\"\"Downloads a blob from the bucket.\"\"\"\n    # The ID of your GCS bucket\n    # bucket_name = \"your-bucket-name\"\n\n    # The ID of your GCS object\n    # source_blob_name = \"storage-object-name\"\n\n    # The path to which the file should be downloaded\n    # destination_file_name = \"local/path/to/file\"\n\n    storage_client = storage.Client()\n    bucket = storage_client.bucket(bucket_name)\n\n    # Construct a client side representation of a blob.\n    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n    # any content from Google Cloud Storage. As we don't need additional data,\n    # using `Bucket.blob` is preferred here.\n    blob = bucket.blob(source_blob_name)\n    content = blob.download_as_string()\n\n    print(\"Downloaded storage object {} from bucket {}\".format(source_blob_name, bucket_name))\n    return content"}, {"cell_type": "code", "execution_count": null, "id": "811353a4-a608-46a7-a3ab-9fc027e86767", "metadata": {}, "outputs": [], "source": "def message_handler(data):\n    clear_output(wait=True)\n    print('Message Handler...')\n    message = json.loads(data)\n    print(message)\n\ndef batch_handler(batch):\n    print('Batch Handler...')\n    \n    clear_output(wait=True)\n    print('Batch Handler...')\n    \n    firstMessage = json.loads(batch[0])\n    lastMessage = json.loads(batch[-1])\n    \n    # Create unique file name for batch\n    fileName = input_folder_name + time.strftime(\"%Y-%m-%d-%H-%M-\") + str(firstMessage['id']) + '-' + str(lastMessage['id']) + '.json'\n    \n    # Get content of batch\n    content = ''\n    for data in batch:\n        message = json.loads(data)\n        content = content + json.dumps(message) + '\\n'\n    \n    # Upload batch to cloud storage\n    upload_blob_from_memory(project_bucket_name, content, fileName)\n    \n    \ndef send_tweets_to_client_connection(client_connection, topic):\n    # Create twitter stream\n    twitter_stream = TweetStream(\\\n        consumer_key\\\n        , consumer_secret\\\n        , access_token\\\n        , access_token_secret\\\n        , client_connection\\\n        , message_Handler=message_handler\\\n        , rate_limit_delay=0.5\\\n        #, tweet_limit=10\\\n        #, time_limit=5\\\n        #, batch_size=5\\\n        #, batch_handler=batch_handler\\\n        )\n    \n    # Filter for topic\n    twitter_stream.filter(track=topic, languages=[\"en\"])"}, {"cell_type": "code", "execution_count": null, "id": "6e87152b", "metadata": {}, "outputs": [], "source": "def start_realtime_process(topic):\n     # Get host name and port number for service.\n     host = socket.gethostname()\n     port = 5555\n    \n     # Initialize a socket\n     s = socket.socket()\n     s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    \n     # Binding host and port\n     s.bind((host, port))\n\n     print(\"Listening on port {} with topic {}:\".format(port,topic))\n\n     # Waiting for client connection\n     s.listen(5)\n    \n     # Establish connection with client\n     client_connection, addr = s.accept()  \n\n     # Start streaming tweets to client\n     with client_connection:\n         print(\"Connected with client: \" + str(addr))\n\n         # Send tweets to client through the socket connection\n         send_tweets_to_client_connection(client_connection, topic)"}, {"cell_type": "code", "execution_count": null, "id": "97964fc8-ae18-438c-86a7-ee77ee806d38", "metadata": {}, "outputs": [], "source": "def start_batch_process(topic):\n    \n    # Create twitter stream\n    twitter_stream = TweetStream(\\\n        consumer_key\\\n        , consumer_secret\\\n        , access_token\\\n        , access_token_secret\\\n        #, message_Handler=message_handler\\\n        #, rate_limit_delay=0.1\\\n        #, tweet_limit=batch_size\\\n        #, time_limit=20\\\n        , batch_size=batch_size\\\n        , batch_handler=batch_handler\\\n        )\n    \n    # Filter for topic\n    twitter_stream.filter(track=topic, languages=[\"en\"])"}, {"cell_type": "code", "execution_count": null, "id": "af4fb052", "metadata": {}, "outputs": [], "source": "if __name__ == \"__main__\":\n    \n#     # Get topic and is_realtime from args\n#     args = sys.argv[1:]\n#     if len(args) == 1:\n#         topic = args[0]\n#     if len(args) == 2:\n#         is_realtime = bool(args[1])\n\n#     parser = argparse.ArgumentParser(\n#         description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter,\n#     )\n#     parser.add_argument(\"project_number\", help=\"Your Google Cloud Project Number\")\n#     parser.add_argument(\"cloud_region\", help=\"Your Cloud Region, e.g. 'us-central1'\")\n#     parser.add_argument(\"zone_id\", help=\"Your Zone ID, e.g. 'a'\")\n#     parser.add_argument(\"topic_id\", help=\"Your topic ID\")\n\n#     args = parser.parse_args()\n        \n    if is_realtime == True:\n        print(\"Starting real-time process with topic = {}\".format(topic))\n        start_realtime_process(topic)\n        print(\"Finished.\")\n    else:\n        print(\"Starting batch process with topic = {}\".format(topic))\n        start_batch_process(topic)\n        print(\"Finished.\")"}, {"cell_type": "code", "execution_count": null, "id": "575a1445-dad3-4c57-a273-1a3175e9704e", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"interpreter": {"hash": "aea1e1c6019b0b94b776c1de20443eea7958a54dce1cb1d96e169a524b7b6729"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}