{"cells":[{"cell_type":"markdown","id":"1a801701-bd23-4f1d-af9d-efd8a746d8e8","metadata":{},"source":["https://towardsdatascience.com/my-absolute-go-to-for-sentiment-analysis-textblob-3ac3a11d524"]},{"cell_type":"code","execution_count":null,"id":"64142eb6-689c-40b6-91fe-cd038b019028","metadata":{},"outputs":[],"source":["!pip install textblob\n","!pip install findspark"]},{"cell_type":"code","execution_count":null,"id":"811353a4-a608-46a7-a3ab-9fc027e86767","metadata":{},"outputs":[],"source":["# import necessary packages\n","import os\n","import json\n","import time\n","import subprocess\n","import pyspark\n","import findspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark.sql import functions as F\n","from textblob import TextBlob\n","\n","from IPython.display import clear_output"]},{"cell_type":"code","execution_count":null,"id":"9713fff8","metadata":{},"outputs":[],"source":["findspark.init()"]},{"cell_type":"code","execution_count":null,"id":"6e87152b","metadata":{},"outputs":[],"source":["# # Create streaming server process\n","# server_process = subprocess.Popen([\"python\", r\"tweet_stream_producer.py\", \"Test\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","\n","# # Check is listening\n","# with server_process.stdout:\n","#     for line in iter(server_process.stdout.readline, b''): \n","#         if \"Listening\" in str(line):\n","#             print(line)\n","#             break\n","#         else:\n","#             server_process.terminate()\n","#             print(\"Process terminated, Return code:\", server_process.returncode)\n","#             print(\"Something went wrong!\")"]},{"cell_type":"code","execution_count":null,"id":"af4fb052","metadata":{},"outputs":[],"source":["# # Kill server process\n","# server_process.terminate()\n","# print(\"Process terminated, Return code:\", server_process.returncode)\n","# server_process = None"]},{"cell_type":"code","execution_count":null,"id":"4c8407aa-efd0-49f8-9206-7c5c1297abd9","metadata":{},"outputs":[],"source":["def json_load(text):\n","    return json.loads(text)"]},{"cell_type":"code","execution_count":null,"id":"9b576e31-21bf-458f-a431-014a6a81f761","metadata":{},"outputs":[],"source":["def get_message(text):\n","    msg = json.loads(text)\n","    # if tweet is longer than 140 characters\n","    if \"extended_tweet\" in msg:\n","        return str(msg['extended_tweet']['full_text'])\n","    else:\n","        return str(msg['text'])"]},{"cell_type":"code","execution_count":null,"id":"9e9e4a2d-6050-4e46-96e5-4f023aa18673","metadata":{},"outputs":[],"source":["def get_tweet_field(text, field):\n","    msg = json.loads(text)\n","    if '/' in field:\n","        fields = field.split('/')\n","        fieldDepth = len(fields)\n","        f = msg\n","        for i in range(fieldDepth):\n","            if(f is None):\n","                return None\n","            if i == fieldDepth - 1:\n","                return str(f[fields[i]]) \n","            else:\n","                f = f[fields[i]]\n","    else:\n","        return str(msg[field])"]},{"cell_type":"code","execution_count":null,"id":"0077686e-aed4-418e-9e49-9723877afa68","metadata":{},"outputs":[],"source":["def get_analysis(score):\n","    if score < 0:\n","        return 'Negative'\n","    elif score == 0:\n","        return 'Neutral'\n","    else:\n","        return 'Positive'"]},{"cell_type":"code","execution_count":null,"id":"69517450-b31a-44b7-8000-00ccc59bcb24","metadata":{},"outputs":[],"source":["def preprocessing(tweets):\n","    \n","#     # Convert to json\n","#     json_load_udf = udf(json_load, StringType())\n","#     tweets = tweets.withColumn(\"json\", json_load_udf(\"value\"))\n","    \n","    # Get id\n","    get_tweet_field_udf = udf(get_tweet_field, StringType())\n","    tweets = tweets.withColumn(\"id\", get_tweet_field_udf(\"value\", lit('id')))\n","    \n","    # Get created_at\n","    get_tweet_field_udf = udf(get_tweet_field, StringType())\n","    tweets = tweets.withColumn(\"created_at\", get_tweet_field_udf(\"value\", lit('created_at')))\n","    \n","    # Get place full name\n","    get_tweet_field_udf = udf(get_tweet_field, StringType())\n","    tweets = tweets.withColumn(\"place_full_name\", get_tweet_field_udf(\"value\", lit('place/full_name')))\n","    \n","    # Get place country\n","    get_tweet_field_udf = udf(get_tweet_field, StringType())\n","    tweets = tweets.withColumn(\"place_country\", get_tweet_field_udf(\"value\", lit('place/country')))\n","    \n","    # Get place country code\n","    get_tweet_field_udf = udf(get_tweet_field, StringType())\n","    tweets = tweets.withColumn(\"place_country_code\", get_tweet_field_udf(\"value\", lit('place/country_code')))\n","    \n","    # Get message\n","    get_message_udf = udf(get_message, StringType())\n","    tweets = tweets.withColumn(\"message\", get_message_udf(\"value\"))\n","    \n","    # Get cleaned words from message for analysis\n","    #tweets = tweets.na.replace('', None)\n","    #tweets = tweets.na.drop()\n","    tweets = tweets.withColumn('words', tweets.message)\n","    tweets = tweets.withColumn('words', F.regexp_replace('words', r'http\\S+', ''))\n","    tweets = tweets.withColumn('words', F.regexp_replace('words', '@\\w+', ''))\n","    tweets = tweets.withColumn('words', F.regexp_replace('words', '#', ''))\n","    tweets = tweets.withColumn('words', F.regexp_replace('words', 'RT', ''))\n","    tweets = tweets.withColumn('words', F.regexp_replace('words', ':', ''))\n","    \n","    # Drop unnesscessary data\n","    tweets = tweets.drop(\"value\")\n","    #tweets = tweets.drop(\"json\")\n","    \n","    return tweets"]},{"cell_type":"code","execution_count":null,"id":"be430afc-52f8-4665-90ed-9fd2a61910cd","metadata":{},"outputs":[],"source":["# Text classification using TextBlob\n","def polarity_detection(text):\n","    return TextBlob(text).sentiment.polarity\n","def subjectivity_detection(text):\n","    return TextBlob(text).sentiment.subjectivity\n","def text_classification(tweets):\n","    \n","    # polarity detection\n","    polarity_detection_udf = udf(polarity_detection, StringType())\n","    tweets = tweets.withColumn(\"polarity\", polarity_detection_udf(\"words\"))\n","    \n","    # subjectivity detection\n","    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n","    tweets = tweets.withColumn(\"subjectivity\", subjectivity_detection_udf(\"words\"))\n","    \n","    # analysis\n","    get_analysis_udf = udf(get_analysis, StringType())\n","    tweets = tweets.withColumn('analysis', get_analysis_udf('polarity'))\n","    \n","    return tweets"]},{"cell_type":"code","execution_count":null,"id":"2665ee39-1c04-4ff9-b34b-2b28687e3163","metadata":{},"outputs":[],"source":["#import libraries to visualize the results from stream\n","import time\n","from IPython import display\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas\n","\n","def visualize_results_from_stream():\n","\n","    get_ipython().run_line_magic('matplotlib', 'inline')\n","    count = 0\n","    while count < 5:\n","\n","        time.sleep(5)\n","        top_10_tags = sqlContext.sql( 'Select hashtag, count from tweets' )\n","        top_10_df = top_10_tags.toPandas()\n","        display.clear_output(wait=True)\n","        plt.figure( figsize = ( 10, 8 ) )\n","        sns.barplot( x=\"count\", y=\"hashtag\", data=top_10_df)\n","        plt.show()\n","        count = count + 1\n","        #     print(count)"]},{"cell_type":"code","execution_count":null,"id":"bf3c4dba-b64c-4f94-8452-3571b19b15e6","metadata":{},"outputs":[],"source":["# import necessary packages\n","import socket\n","import pandas as pd\n","from pyspark import SparkContext\n","from pyspark.streaming import StreamingContext\n","from pyspark.sql import SQLContext\n","from pyspark.sql.functions import desc, explode, split\n","\n","spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n","\n","#sc = SparkContext()\n","sc = spark.sparkContext\n","ssc = StreamingContext(sc, 5)\n","#socket_stream = ssc.socketTextStream(socket.gethostname(), 5555)\n","# raw_stream = spark.readStream \\\n","#                     .format(\"socket\") \\\n","#                     .option(\"host\", socket.gethostname()) \\\n","#                     .option(\"port\", 5555) \\\n","#                     .load()\n","raw_stream = ssc.readStream.text('gs://cloud-project-bucket-22/Data/*').load()\n","#sqlContext = SQLContext(sc)\n","\n","# lines of tweets with socket_stream window of size 10, or 10 #seconds windows of time\n","lines = raw_stream.window(10)\n","#lines = raw_stream\n"]},{"cell_type":"code","execution_count":null,"id":"0d99cb71-8947-453a-9ef5-c380a2395067","metadata":{},"outputs":[],"source":["def process_row(row):\n","    print(row)\n","    \n","def process_batch(df, epoch_id):\n","    clear_output(wait=True)\n","    print('Process batch...')\n","    print(df.head(5))"]},{"cell_type":"code","execution_count":null,"id":"b830e516-5c84-412d-bc8f-2f6a59473410","metadata":{},"outputs":[],"source":[" # Start running the query that prints the running counts to the console\n","tweets = lines\n","tweets = preprocessing(lines)\n","tweets = text_classification(tweets)\n","\n","# Extract analytics here\n","\n","# Visualize the query\n","query = tweets.writeStream.foreachBatch(process_batch).start()\n","query.awaitTermination()\n","\n","# Mutiple streams\n","# val query1 = df.writeStream.start()\n","# val query2 = df.writeStream.start()\n","\n","# spark.streams.awaitAnyTermination()"]},{"cell_type":"code","execution_count":null,"id":"002ce511-4c10-4989-a950-12b604a6dc60","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"643785bd-ddc7-4fb1-9249-7024aa2c5541","metadata":{},"outputs":[],"source":["# just a tuple to assign names\n","#from collections import namedtuple\n","#fields = (\"hashtag\", \"count\" )\n","#Tweet = namedtuple( 'Tweet', fields )\n","#tweets = lines.map(lambda tweet: (json.loads(tweet)['id'], json.loads(tweet)['text']))\n","#tweets = lines.map(lambda tweet: (json.loads(tweet)['id'], json.loads(tweet)['text']))\n","#tweets.foreachRDD( lambda rdd: rdd.toDF()):\n","#lines.foreachRDD(process_batch)\n","#process_batch(lines).start()\n","#words = lines.flatMap(lambda text: text.split(\" \"))\n","#pairs = words.map(lambda word: ( word.lower(), 1 ))\n","#wordCounts = pairs.reduceByKey( lambda a, b: a + b ) \n","#wordCounts.pprint()\n","#tweets.print()\n","\n","\n","#.registerTempTable(\"tweets\")))\n","\n","# # here we apply different operations on the tweets and save them to #a temporary sql table\n","# (lines.map(lambda tweet: Tweet(json.loads(text)['id'], json.loads(text)['text']))\n","# .flatMap( lambda text: text.split( \" \" ))\n","#     # Lower cases the word\n","#     .map( lambda word: ( word.lower(), 1 ) )\n","#     .reduceByKey( lambda a, b: a + b )\n","#     # Stores in a Tweet Object\n","#     .map( lambda rec: Tweet( rec[0], rec[1] ) )\n","#     # Sorts Them in a dataframe\n","#     .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n","#     .limit(10).registerTempTable(\"tweets\") ) )\n","\n","    # Registers only top 10 words to a table.\n","#     ( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n","#       # Checks for    hashtag calls  \n","#       #.filter( lambda word: word.lower().startswith(\"#\") ) \n","#       .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n","#       .reduceByKey( lambda a, b: a + b ) \n","#      # Stores in a Tweet Object\n","#       .map( lambda rec: Tweet( rec[0], rec[1] ) )\n","#      # Sorts Them in a dataframe\n","#       .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n","#      # Registers only top 10 hashtags to a table.\n","#       .limit(10).registerTempTable(\"tweets\") ) )\n","\n"]},{"cell_type":"code","execution_count":null,"id":"13856e23-54f3-4090-8c42-55b2d47135c5","metadata":{},"outputs":[],"source":["# start streaming and wait couple of minutes to get enought tweets\n","#ssc.start()\n","#ssc.awaitTermination()"]},{"cell_type":"code","execution_count":null,"id":"75c231f2-e421-4e2d-a1bd-8559f375606a","metadata":{},"outputs":[],"source":["# stop streaming and wait couple of minutes to get enought tweets\n","#ssc.stop(stopSparkContext=True, stopGraceFully=False)"]}],"metadata":{"interpreter":{"hash":"aea1e1c6019b0b94b776c1de20443eea7958a54dce1cb1d96e169a524b7b6729"},"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}
