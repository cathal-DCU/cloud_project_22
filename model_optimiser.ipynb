{"cells": [{"cell_type": "code", "execution_count": 2, "id": "c121d5c4-f489-4cba-99d5-27d9ff59b050", "metadata": {}, "outputs": [], "source": "# https://www.ateam-oracle.com/post/multiclass-text-classification-crossvalidation-with-pyspark-pipelines\n\nfrom timeit import default_timer as timer\nimport datetime\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom pyspark import SparkConf\nfrom pyspark import SparkContext\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression, OneVsRest\nfrom pyspark.ml.classification import NaiveBayes, LinearSVC\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import IDF\nfrom pyspark.ml.feature import NGram\nfrom pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, IntegerType, TimestampType, StringType"}, {"cell_type": "code", "execution_count": 3, "id": "2d8b5c92-e6a7-4747-acda-606383523abc", "metadata": {}, "outputs": [], "source": "###################################################################\n########## general setting to configure before executing ##########\n# how many parallel threads should the crossvalidator use\nparallelExec=4\n\n# should the crossvalidator collect submodel data\ntrackSubModels=False\n\n# how many folds should crossvalidator use\nnumberFolds=3\n\n# Path to save the best model to\nmodelSavePath = \"gs://cloud-project-bucket-3/modeldir2\"\n\n# data file to load\ndataToLoad = \"gs://cloud-project-bucket-3/Sentiment_Analysis_Dataset.csv\"\n\nconf = SparkConf().setMaster(\"local[*]\").setAppName(\"multigridsearch\")\n###################################################################"}, {"cell_type": "code", "execution_count": 4, "id": "8ed069e0-460f-4c12-96af-615688dab7ec", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/03/09 09:27:32 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n22/03/09 09:27:32 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n22/03/09 09:27:32 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n22/03/09 09:27:32 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "sc = SparkContext(conf=conf)\nsc.setLogLevel(\"ERROR\")\nspark = SparkSession(sc)"}, {"cell_type": "code", "execution_count": 5, "id": "a8e799b3-85b3-48d8-ad93-91922eb0ab5d", "metadata": {}, "outputs": [], "source": "stoplist = stopwords.words('english')\n# stopwords_download = nltk.download('stopwords')\n# stop_words = stopwords_download.read().split('\\n')"}, {"cell_type": "code", "execution_count": 6, "id": "20ad8f67-4135-4bbe-8699-6d5150f6b9d8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+--------------------+\n|label|                text|\n+-----+--------------------+\n|    0|i think to much o...|\n|    0|Tuesday is a rain...|\n|    0|Dad was admitted ...|\n|    0|hoping I can fall...|\n|    0|Finished the seco...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"}], "source": "\"\"\"\ncols = ['sentiment','id','date','query_string','user','text']\nschema = StructType([\n    StructField('sentiment', IntegerType(), True),\n    StructField('id', IntegerType(), True),\n    StructField('date', StringType(), True),\n    StructField('query_string', StringType(), True),\n    StructField('user', StringType(), True),\n    StructField('text', StringType(), True)])\n    \ndata = spark.read.csv(dataToLoad,header=False,schema=schema)  \n\"\"\"\ndata = spark.read.csv(dataToLoad,header=True)\ndata = data.withColumn(\"label\", data[\"label\"].cast(IntegerType()))\ndata = data.drop('_c0','id', 'flag', 'user', 'date')\ndata = data.sample(False, .0025, 42)\ndata.show(5)\n"}, {"cell_type": "code", "execution_count": 7, "id": "3954cb38-863b-452e-937d-2f7d4b938141", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "data partitions #: 4\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 2:==============>                                            (1 + 3) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "data size :  4001\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# how many partitions if the data being sliced into by default\nprint ('data partitions #:', data.rdd.getNumPartitions())\n# What is the size of our dataset\nprint ('data size : ', data.count())"}, {"cell_type": "code", "execution_count": 8, "id": "a6c3d9d0-c08c-4ac3-af47-e3a483deec16", "metadata": {}, "outputs": [{"data": {"text/plain": "[('label', 'int'), ('text', 'string')]"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": "data.dtypes"}, {"cell_type": "code", "execution_count": 9, "id": "b00106f6-6b6d-46fc-8293-9772d290d60f", "metadata": {}, "outputs": [], "source": "###################################################################\n### What features, algorithms and hyperparameters will be used ####"}, {"cell_type": "code", "execution_count": 10, "id": "f2bdedb5-5baa-4e19-b5b1-662833fce938", "metadata": {}, "outputs": [], "source": "# tokenize our data into individual words. If you only wanted to use unigrams, you could use just this step and not need the ngram step as well. You would need to adjust column names.\n# any word less than this lenth will be removed from the feature list. For example, is stop words doesn't catch \"a, at, of\" and min length is 3, those are gone.\nregexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\", minTokenLength=3)\nminimumWordLength = [2, 3, 4]"}, {"cell_type": "code", "execution_count": 11, "id": "ec33e5fe-fe53-439f-9924-030bb9d3fd39", "metadata": {}, "outputs": [], "source": "# convert our text labels to numerical values\nlabel_stringIdx = StringIndexer(inputCol=\"label\", outputCol=\"num_label\", handleInvalid=\"keep\")"}, {"cell_type": "code", "execution_count": 12, "id": "9c93dd2d-cf9c-4aab-8339-0c4c88d2a421", "metadata": {}, "outputs": [], "source": "# remove stopwords using our custom stopword list\n# stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=stop_words)\nstopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=stoplist)"}, {"cell_type": "code", "execution_count": 13, "id": "b6d20373-fa74-4ae2-ad0d-025a16e5409e", "metadata": {}, "outputs": [], "source": "# split words into groups. ngramSize defines the group size. For example, 1 is unigrams, 2 is bigrams etc...\nngramer = NGram(inputCol='filtered', outputCol='ngrams')\nngramSize = [1, 2]"}, {"cell_type": "code", "execution_count": 14, "id": "ff2083ab-b667-4422-b4b2-a382b7e5af25", "metadata": {}, "outputs": [], "source": "countVectors = CountVectorizer(inputCol=\"ngrams\", outputCol=\"features\", vocabSize=100000, minDF=5)\nvocabularySize = [10000, 50000, 100000]\nminDF = [3, 5]"}, {"cell_type": "code", "execution_count": 15, "id": "a85557dd-3bd5-4d73-903d-966e1266c1fc", "metadata": {}, "outputs": [], "source": "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\nregParam = [0.01, 0.1, 0.3, 0.5]\nelasticNetParam = [0, .5, 1]"}, {"cell_type": "code", "execution_count": 16, "id": "51ab8a7b-31dd-4bef-9694-1b1100de381b", "metadata": {}, "outputs": [], "source": "rf = RandomForestRegressor(subsamplingRate=0.15, featuresCol='features', labelCol='num_label')\nnumberTrees = [10, 20, 30]\nmaxDepth =  [5, 10]"}, {"cell_type": "code", "execution_count": 17, "id": "3fa895b4-87e6-4e4b-ab46-c891533f97a7", "metadata": {}, "outputs": [], "source": "nb = NaiveBayes(smoothing=1)\nnbSmoothing =  [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]"}, {"cell_type": "code", "execution_count": 18, "id": "8aa2b13f-6862-4439-adb7-c0d038bf5229", "metadata": {}, "outputs": [], "source": "idf = IDF(inputCol=\"features\", outputCol=\"idf\", minDocFreq=5)\nminDocFreq=[5, 10]"}, {"cell_type": "code", "execution_count": 19, "id": "be630181-9e79-43df-aa61-1b57ad679f27", "metadata": {}, "outputs": [], "source": "lsvc = LinearSVC()\nlvcsMaxIter = [10, 50, 100]\nlvcsRegParam = [0.001, 0.01, 1.0,10.0]\novr = OneVsRest(classifier=lsvc)\n###################################################################"}, {"cell_type": "code", "execution_count": 20, "id": "d56491b2-9273-431d-ab97-d617f5c5fec7", "metadata": {}, "outputs": [], "source": "# set pipeline to en empty list of pipeline stages\npipeline = Pipeline(stages=[])\n\n###################################################################"}, {"cell_type": "code", "execution_count": 21, "id": "494184ec-afd7-4307-8367-04b1d50a9d13", "metadata": {}, "outputs": [], "source": "######### define our various grids we want to execute #############\ncv_stages = [regexTokenizer, label_stringIdx, stopwordsRemover, ngramer, countVectors, lr]\ncv_paramgrid = ParamGridBuilder().baseOn({pipeline.stages:cv_stages}) \\\n    .addGrid(regexTokenizer.minTokenLength, minimumWordLength) \\\n    .addGrid(ngramer.n, ngramSize)\\\n    .addGrid(countVectors.vocabSize, vocabularySize)\\\n    .addGrid(countVectors.minDF, minDF) \\\n    .addGrid(lr.regParam, regParam) \\\n    .addGrid(lr.elasticNetParam, elasticNetParam) \\\n    .build()\n"}, {"cell_type": "code", "execution_count": 22, "id": "934e0386-ecd1-4857-8d3a-a2940c40579c", "metadata": {}, "outputs": [], "source": "rf_stages = [regexTokenizer, label_stringIdx, stopwordsRemover, ngramer, countVectors, rf]"}, {"cell_type": "code", "execution_count": 23, "id": "3524fbf3-2f03-4b04-b861-04739c411bc9", "metadata": {}, "outputs": [], "source": "rf_paramgrid = ParamGridBuilder().baseOn({pipeline.stages:rf_stages}) \\\n    .addGrid(regexTokenizer.minTokenLength, minimumWordLength) \\\n    .addGrid(ngramer.n, ngramSize) \\\n    .addGrid(countVectors.vocabSize, vocabularySize) \\\n    .addGrid(countVectors.minDF, minDF) \\\n    .addGrid(rf.numTrees, numberTrees) \\\n    .addGrid(rf.maxDepth, maxDepth)\\\n    .build()"}, {"cell_type": "code", "execution_count": 24, "id": "3ac19952-7a3e-43f6-808e-88ec4af4d95e", "metadata": {}, "outputs": [], "source": "idf_stages = [regexTokenizer, label_stringIdx, stopwordsRemover, ngramer, countVectors, idf, lr]\nidf_paramgrid = ParamGridBuilder().baseOn({pipeline.stages:idf_stages}) \\\n    .addGrid(regexTokenizer.minTokenLength, minimumWordLength) \\\n    .addGrid(ngramer.n, ngramSize) \\\n    .addGrid(countVectors.vocabSize, vocabularySize) \\\n    .addGrid(countVectors.minDF, minDF) \\\n    .addGrid(idf.minDocFreq, minDocFreq)\\\n    .build()"}, {"cell_type": "code", "execution_count": 25, "id": "83c225b2-a277-44e7-b6aa-a92be745e52e", "metadata": {}, "outputs": [], "source": "nb_stages = [regexTokenizer, label_stringIdx, stopwordsRemover, ngramer, countVectors, nb]\nnb_paramgrid = ParamGridBuilder().baseOn({pipeline.stages:nb_stages}) \\\n    .addGrid(regexTokenizer.minTokenLength, minimumWordLength) \\\n    .addGrid(ngramer.n, ngramSize) \\\n    .addGrid(countVectors.vocabSize, vocabularySize) \\\n    .addGrid(countVectors.minDF, minDF) \\\n    .addGrid(nb.smoothing, nbSmoothing) \\\n    .build()"}, {"cell_type": "code", "execution_count": 26, "id": "d0834818-aab9-47c8-9cc5-4bc3be7b99af", "metadata": {}, "outputs": [], "source": "lsvc_stages = [regexTokenizer, label_stringIdx, stopwordsRemover, ngramer, countVectors, ovr]\nlsvc_paramgrid = ParamGridBuilder().baseOn({pipeline.stages:lsvc_stages}) \\\n    .addGrid(regexTokenizer.minTokenLength, minimumWordLength) \\\n    .addGrid(ngramer.n, ngramSize) \\\n    .addGrid(countVectors.vocabSize, vocabularySize) \\\n    .addGrid(countVectors.minDF, minDF) \\\n    .addGrid(lsvc.maxIter, lvcsMaxIter) \\\n    .addGrid(lsvc.regParam, lvcsRegParam) \\\n    .build()"}, {"cell_type": "code", "execution_count": 27, "id": "7813cbd3-6724-4fd4-94fc-c08aa59bf592", "metadata": {}, "outputs": [], "source": "# gridloop = [cv_paramgrid, idf_paramgrid]\n# gridloop = [cv_paramgrid]\ngridloop = [cv_paramgrid, rf_paramgrid, idf_paramgrid, nb_paramgrid, lsvc_paramgrid]\n\n###################################################################"}, {"cell_type": "code", "execution_count": 28, "id": "ed06ec2b-0e08-42df-bb27-774a4b973cbc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Number of parameter combinations being tested  1368\nstarting crossvalidation at  2022-03-09 09:27:41.426468 \n\n"}], "source": "# how many parameter combinations are about to be tested. Warning - this can quickly get out of hand\nparamCombo = 0\nfor grid in gridloop:\n    paramCombo = paramCombo + len(grid)\nprint (\"Number of parameter combinations being tested \", paramCombo)\n\nprint(\"starting crossvalidation at \", datetime.datetime.now(), \"\\n\")"}, {"cell_type": "code", "execution_count": 29, "id": "6c983d18-e8b5-4448-8033-bc506cd5c1b6", "metadata": {}, "outputs": [], "source": "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")"}, {"cell_type": "code", "execution_count": 30, "id": "88bdb9f1-cf69-445f-a736-97f8b04c6180", "metadata": {}, "outputs": [], "source": "# Since a loop is used, we manually track which model between loops has the highest accuracy\nbestAcc = 0"}, {"cell_type": "code", "execution_count": null, "id": "602e94ae-5b3c-43bd-915d-ed2df70fec69", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/03/09 09:57:16 WARN org.apache.spark.storage.BlockManager: Asked to remove block broadcast_164320, which does not exist\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "max score for this grid  0.689248862955272\nthis model has greater accuracy. Old acc  0  new acc  0.689248862955272\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "max score for this grid  0.0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "max score for this grid  0.6872384492090453\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "max score for this grid  0.34542898513832004\n"}, {"name": "stderr", "output_type": "stream", "text": "22/03/09 10:23:07 ERROR org.apache.spark.ml.util.Instrumentation: java.lang.IllegalArgumentException: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.LinearSVC.$anonfun$train$1(LinearSVC.scala:212)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:171)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:76)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat sun.reflect.GeneratedMethodAccessor288.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n22/03/09 10:23:07 ERROR org.apache.spark.ml.util.Instrumentation: java.lang.IllegalArgumentException: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.LinearSVC.$anonfun$train$1(LinearSVC.scala:212)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:171)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:76)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat sun.reflect.GeneratedMethodAccessor288.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n22/03/09 10:23:07 ERROR org.apache.spark.ml.util.Instrumentation: java.lang.IllegalArgumentException: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.LinearSVC.$anonfun$train$1(LinearSVC.scala:212)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:171)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:76)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat sun.reflect.GeneratedMethodAccessor288.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n22/03/09 10:23:08 ERROR org.apache.spark.ml.util.Instrumentation: java.lang.IllegalArgumentException: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.LinearSVC.$anonfun$train$1(LinearSVC.scala:212)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:171)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:76)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat sun.reflect.GeneratedMethodAccessor288.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n22/03/09 10:23:08 ERROR org.apache.spark.ml.util.Instrumentation: java.lang.IllegalArgumentException: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.LinearSVC.$anonfun$train$1(LinearSVC.scala:212)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:171)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:76)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat sun.reflect.GeneratedMethodAccessor288.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n22/03/09 10:23:08 ERROR org.apache.spark.ml.util.Instrumentation: java.lang.IllegalArgumentException: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.LinearSVC.$anonfun$train$1(LinearSVC.scala:212)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:171)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:76)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat sun.reflect.GeneratedMethodAccessor288.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n22/03/09 10:23:08 ERROR org.apache.spark.ml.util.Instrumentation: java.lang.IllegalArgumentException: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.LinearSVC.$anonfun$train$1(LinearSVC.scala:212)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:171)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:76)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat sun.reflect.GeneratedMethodAccessor288.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n22/03/09 10:23:08 ERROR org.apache.spark.ml.util.Instrumentation: java.lang.IllegalArgumentException: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.LinearSVC.$anonfun$train$1(LinearSVC.scala:212)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:171)\n\tat org.apache.spark.ml.classification.LinearSVC.train(LinearSVC.scala:76)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat sun.reflect.GeneratedMethodAccessor288.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n"}, {"ename": "IllegalArgumentException", "evalue": "requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)", "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m starttime \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m      5\u001b[0m crossval \u001b[38;5;241m=\u001b[39m CrossValidator(estimatorParamMaps\u001b[38;5;241m=\u001b[39mgrid,\n\u001b[1;32m      6\u001b[0m                                  estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[1;32m      7\u001b[0m                                  evaluator\u001b[38;5;241m=\u001b[39mevaluator,\n\u001b[1;32m      8\u001b[0m                                  numFolds\u001b[38;5;241m=\u001b[39mnumberFolds,\n\u001b[1;32m      9\u001b[0m                                  parallelism\u001b[38;5;241m=\u001b[39mparallelExec,\n\u001b[1;32m     10\u001b[0m                                  collectSubModels\u001b[38;5;241m=\u001b[39mtrackSubModels)\n\u001b[0;32m---> 11\u001b[0m cvModel \u001b[38;5;241m=\u001b[39m \u001b[43mcrossval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(\"Time to crossval\", timer() - starttime)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# get the accuracy metrics for the models. This is a list.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m avgMetricsGrid \u001b[38;5;241m=\u001b[39m cvModel\u001b[38;5;241m.\u001b[39mavgMetrics\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:161\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/tuning.py:687\u001b[0m, in \u001b[0;36mCrossValidator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    684\u001b[0m train \u001b[38;5;241m=\u001b[39m datasets[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m    686\u001b[0m tasks \u001b[38;5;241m=\u001b[39m _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam)\n\u001b[0;32m--> 687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, metric, subModel \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(\u001b[38;5;28;01mlambda\u001b[39;00m f: f(), tasks):\n\u001b[1;32m    688\u001b[0m     metrics[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (metric \u001b[38;5;241m/\u001b[39m nFolds)\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collectSubModelsParam:\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/multiprocessing/pool.py:868\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 868\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/tuning.py:687\u001b[0m, in \u001b[0;36mCrossValidator._fit.<locals>.<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    684\u001b[0m train \u001b[38;5;241m=\u001b[39m datasets[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m    686\u001b[0m tasks \u001b[38;5;241m=\u001b[39m _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam)\n\u001b[0;32m--> 687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, metric, subModel \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(\u001b[38;5;28;01mlambda\u001b[39;00m f: \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, tasks):\n\u001b[1;32m    688\u001b[0m     metrics[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (metric \u001b[38;5;241m/\u001b[39m nFolds)\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collectSubModelsParam:\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/tuning.py:69\u001b[0m, in \u001b[0;36m_parallelFitTasks.<locals>.singleTask\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingleTask\u001b[39m():\n\u001b[0;32m---> 69\u001b[0m     index, model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodelIter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# TODO: duplicate evaluator to take extra params from input\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m#  Note: Supporting tuning params in evaluator need update method\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m#  `MetaAlgorithmReadWrite.getAllNestedStages`, make it return\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m#  all nested stages and evaluators\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     metric \u001b[38;5;241m=\u001b[39m eva\u001b[38;5;241m.\u001b[39mevaluate(model\u001b[38;5;241m.\u001b[39mtransform(validation, epm[index]))\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:69\u001b[0m, in \u001b[0;36m_FitMultipleIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo models remaining.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitSingleModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:126\u001b[0m, in \u001b[0;36mEstimator.fitMultiple.<locals>.fitSingleModel\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfitSingleModel\u001b[39m(index):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparamMaps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:159\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(dataset)\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/pipeline.py:114\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    112\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# must be an Estimator\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     transformers\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m indexOfLastEstimator:\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:161\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/classification.py:2924\u001b[0m, in \u001b[0;36mOneVsRest._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m   2920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m classifier\u001b[38;5;241m.\u001b[39mfit(trainingDataset, paramMap)\n\u001b[1;32m   2922\u001b[0m pool \u001b[38;5;241m=\u001b[39m ThreadPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetParallelism(), numClasses))\n\u001b[0;32m-> 2924\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainSingleClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnumClasses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handlePersistence:\n\u001b[1;32m   2927\u001b[0m     multiclassLabeled\u001b[38;5;241m.\u001b[39munpersist()\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/multiprocessing/pool.py:48\u001b[0m, in \u001b[0;36mmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmapstar\u001b[39m(args):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/classification.py:2920\u001b[0m, in \u001b[0;36mOneVsRest._fit.<locals>.trainSingleClass\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m   2918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weightCol:\n\u001b[1;32m   2919\u001b[0m     paramMap[classifier\u001b[38;5;241m.\u001b[39mweightCol] \u001b[38;5;241m=\u001b[39m weightCol\n\u001b[0;32m-> 2920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainingDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparamMap\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:159\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(dataset)\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py:335\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m--> 335\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py:332\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03mFits a Java model to the input dataset.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m    fitted Java model\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n", "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: LinearSVC only supports binary classification. 1 classes detected in LinearSVC_5253b7c8f35a__labelCol"]}], "source": "# using a loop instead of one big grid search to accomodate getting submodel data. With a huge grid, out of memory errors are more likely when collecting subModel data\nfor grid in gridloop:\n    # print (\"running grid \", grid, \"\\n\")\n    starttime = timer()\n    crossval = CrossValidator(estimatorParamMaps=grid,\n                                     estimator=pipeline,\n                                     evaluator=evaluator,\n                                     numFolds=numberFolds,\n                                     parallelism=parallelExec,\n                                     collectSubModels=trackSubModels)\n    cvModel = crossval.fit(data)\n    # print(\"Time to crossval\", timer() - starttime)\n    # get the accuracy metrics for the models. This is a list.\n    avgMetricsGrid = cvModel.avgMetrics\n    # print (avgMetricsGrid)\n    # get the max accuracy metric in the list of accuracy metrics.\n    modelAcc = max(avgMetricsGrid)\n    print(\"max score for this grid \", modelAcc)\n    if (modelAcc > bestAcc):\n        print (\"this model has greater accuracy. Old acc \", bestAcc, \" new acc \", modelAcc)\n        bestModel = cvModel.bestModel\n        bestAcc = modelAcc\n        \"\"\"\n        # print out the params for all the stages of this model\n        for stage in bestModel.stages:\n            print (stage.extractParamMap())\n        \"\"\"\n    # if you are collecting submodel data, this will dump all the param combinations being tested. You can use this with the avgMetricsGrid above to see the accruacy of all your param combos\n    \"\"\"\n    if (trackSubModels) :\n        submods = cvModel.subModels\n        for mods in submods:\n            for mod in mods:\n                for stage in mod.stages:\n                    print(stage.extractParamMap())\n    \"\"\""}, {"cell_type": "code", "execution_count": null, "id": "0a6c4b93-1285-455a-9928-456d32395ab3", "metadata": {}, "outputs": [], "source": "# save the best model for reuse.\nbestModel.save(modelSavePath)\n"}, {"cell_type": "code", "execution_count": null, "id": "89c2e441-ec48-4ab3-bc00-eb6f5bb24249", "metadata": {}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "25ab0e0b-601d-4baa-bc00-02c3c46ee103", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}