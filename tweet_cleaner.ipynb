{"cells": [{"cell_type": "code", "execution_count": 1, "id": "9222858b-617a-44d9-879b-7e90f7091a11", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"}], "source": "import pandas as pd\nimport numpy as np\nimport csv\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\n# %matplotlib inline\nimport pip\nimport seaborn as sns\nimport random\n\nfrom pyspark.ml import PipelineModel\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.model_selection import GridSearchCV\n# import sklearn.externals.joblib\nimport joblib\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nimport re\nfrom collections import Counter\nfrom string import punctuation\n# import tweepy\n# from tweepy import OAuthHandler\nimport json\nfrom wordcloud import WordCloud\nfrom pathlib import Path\n# import chart_studio\n# import chart_studio.plotly as py\n# import plotly.graph_objs as go\n# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n# import cufflinks as cf"}, {"cell_type": "code", "execution_count": 2, "id": "e67c796c-3d5b-400d-930f-49fd5851f6f0", "metadata": {}, "outputs": [], "source": "collected_tweets=\"gs://cloud-project-bucket-3/batman_twitter.csv\"\ncol_names = ['date', 'user_loc', 'followers', 'friends', 'text', 'bbox_coords', \\\n             'full_name', 'country', 'country_code', 'place_type']\ndf_batman = pd.read_csv(collected_tweets, names=col_names)"}, {"cell_type": "code", "execution_count": 3, "id": "895e962d-c963-4e66-a558-149427a00172", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/tmp/ipykernel_2389/3856750605.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n  pd.set_option('display.max_colwidth', -1)\n"}], "source": "pd.set_option('display.max_colwidth', -1)\nplt.style.use('seaborn-white')"}, {"cell_type": "code", "execution_count": 4, "id": "34baa941-7d68-48fd-98f8-660462d6fabc", "metadata": {}, "outputs": [], "source": "# Sort dataframe by date column\ndf_batman['date'] = pd.to_datetime(df_batman['date'])\ndf_batman = df_batman.sort_values(by='date', ascending=True)\ndf_batman = df_batman.reset_index().drop('index', axis=1)"}, {"cell_type": "code", "execution_count": 5, "id": "e7a980de-dfa0-42e2-8fcd-e7f8551a6174", "metadata": {}, "outputs": [], "source": "# helper function to clean tweets\ndef processTweet(tweet):\n    # Remove HTML special entities (e.g. &amp;)\n    tweet = re.sub(r'\\&\\w*;', '', tweet)\n    # Convert @username to AT_USER\n    tweet = re.sub('@[^\\s]+', '', tweet)\n    # Remove tickers\n    tweet = re.sub(r'\\$\\w*', '', tweet)\n    # To lowercase\n    tweet = tweet.lower()\n    # Remove hyperlinks\n    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n    # Remove hashtags\n    tweet = re.sub(r'#\\w*', '', tweet)\n    # Remove Punctuation and split 's, 't, 've with a space for filter\n    tweet = re.sub(r'[' + punctuation.replace('@', '') + ']+', ' ', tweet)\n    # Remove words with 2 or fewer letters\n    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n    # Remove whitespace (including new line characters)\n    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n    # Remove single space remaining at the front of the tweet.\n    tweet = tweet.lstrip(' ')\n    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n    tweet = ''.join(c for c in tweet if c <= '\\uFFFF')\n    return tweet"}, {"cell_type": "code", "execution_count": 6, "id": "a16fb4fc-ccf9-4ab3-bca5-b7453f822da7", "metadata": {}, "outputs": [], "source": "# clean dataframe's text column\ndf_batman['text'] = df_batman['text'].apply(processTweet)"}, {"cell_type": "code", "execution_count": 7, "id": "4ab2f285-3c4d-4285-8942-bc3b88d1721e", "metadata": {}, "outputs": [], "source": "# drop duplicates\ndf_batman = df_batman.drop_duplicates('text')"}, {"cell_type": "code", "execution_count": 8, "id": "2350a801-902c-4628-8de0-e1975ddb557b", "metadata": {}, "outputs": [], "source": "# tokenize helper function\ndef text_process(raw_text):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    # Check characters to see if they are in punctuation\n    nopunc = [char for char in list(raw_text) if char not in string.punctuation]\n\n    # Join the characters again to form the string.\n    nopunc = ''.join(nopunc)\n\n    # Now just remove any stopwords\n    return [word for word in nopunc.lower().split() if word.lower() not in stopwords.words('english')]"}, {"cell_type": "code", "execution_count": 9, "id": "186be571-0fbb-4711-be8a-3822ca23a40d", "metadata": {}, "outputs": [], "source": "def remove_words(word_list):\n    remove = ['batman', '...', '\u201c', '\u201d', '\u2019', '\u2026']\n    return [w for w in word_list if w not in remove]\n"}, {"cell_type": "code", "execution_count": 10, "id": "f1f1224c-e870-438c-b66f-0f4b011693ef", "metadata": {}, "outputs": [], "source": "# tokenize message column and create a column for tokens\ndf_batman.to_csv(\"gs://cloud-project-bucket-3/batman_col_names.csv\")\ndf_batman = df_batman.copy()\ndf_batman['tokens'] = df_batman['text'].apply(text_process)  # tokenize style 1\ndf_batman['no_batman'] = df_batman['tokens'].apply(remove_words)  # tokenize style 2\ndf_batman.to_csv(\"gs://cloud-project-bucket-3/batman_cleaned.csv\")"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}